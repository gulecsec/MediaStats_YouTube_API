{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72443ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "from datetime import datetime, timedelta\n",
    "import isodate #parse\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Data viz packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b18bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'your_API_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e185644",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id='your_channel_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "# Get credentials and create an API client\n",
    "youtube = build(api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56860bb8-b330-494d-9e26-fb08a82b7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channelName, subscribers count, total views, totalVideos, playlistId\n",
    "\n",
    "get_channel_stats(youtube, channel_ids):\n",
    "    \n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_id))\n",
    "    \n",
    "    response = request.execute()\n",
    "\n",
    "    # loop through items\n",
    "    for item in response['items']: # Some channels have \"0\" items\n",
    "        data = {'channelName': item['snippet']['title'],\n",
    "                'subscribers': item['statistics']['subscriberCount'],\n",
    "                'views': item['statistics']['viewCount'],\n",
    "                'totalVideos': item['statistics']['videoCount'],\n",
    "                'playlistId': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "        }\n",
    "        \n",
    "        # Check if the channel has any subscriber milestone\n",
    "        if 'bulletin' in item['contentDetails']:\n",
    "            milestone = item['contentDetails']['bulletin']['resource']\n",
    "            if milestone['kind'] == 'youtube#subscription':\n",
    "                data['milestoneDate'] = milestone['publishedAt']\n",
    "                data['milestoneSubscribers'] = milestone['metadata']['subscriberCount']\n",
    "                \n",
    "        all_data.append(data)\n",
    "        \n",
    "    return(pd.DataFrame(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d985c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_stats = get_channel_stats(response)\n",
    "channel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512da213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids\n",
    "\n",
    "playlist_id = \"your_channel_id\"\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet, contentDetails\",\n",
    "        playlistId=playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token is not None:\n",
    "        request = youtube.playlistItems().list(\n",
    "            part=\"snippet, contentDetails\",\n",
    "            playlistId=playlist_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_page_token)\n",
    "   \n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d636aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Video IDs\n",
    "video_ids=get_video_ids(youtube, playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c72df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the list of videos; channelTitle, title, ...\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "\n",
    "    all_video_info = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet, contentDetails, statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info={}\n",
    "            video_info['video_id']=video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v]=None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "    \n",
    "    return pd.DataFrame(all_video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed4e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get video details \n",
    "df = get_video_details(youtube, video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0bf587",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c82be6-3f62-4b06-894c-3b44a3ae7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df = df.copy()\n",
    "video_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish day in the week\n",
    "video_df['publishedAt'] = video_df['publishedAt'].apply(lambda x: parser.parse(x)) \n",
    "video_df['pushblishDayName'] = video_df['publishedAt'].apply(lambda x: x.strftime(\"%A\"))\n",
    "\n",
    "# convert duration to seconds\n",
    "video_df['durationSecs'] = video_df['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "video_df['durationSecs'] = video_df['durationSecs'].astype('timedelta64[s]')\n",
    "\n",
    "# Create Month & Year columns\n",
    "video_df['Month'] = pd.to_datetime(video_df[\"publishedAt\"]).dt.strftime('%b')\n",
    "video_df['Year'] = pd.to_datetime(video_df['publishedAt']).dt.strftime('%b')\n",
    "video_df['Year'] = video_df['publishedAt'].dt.year\n",
    "\n",
    "# Create Mins & Hours columns for the duration\n",
    "video_df[\"durationMins\"] = (video_df[\"durationSecs\"]/60).round(2).astype(float)\n",
    "video_df[\"durationHours\"] = (video_df[\"durationMins\"]/60).round(2).astype(float)\n",
    "\n",
    "# Add tag count\n",
    "video_df['tagCount'] = video_df['tags'].apply(lambda x: 0 if x is None else len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23cb75-5e06-4908-9220-8f6b013a1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert invalid values to NaN\n",
    "video_df = video_df.replace({'viewCount': {'None': np.nan}, \n",
    "                              'likeCount': {'None': np.nan}, \n",
    "                              'commentCount': {'None': np.nan}})\n",
    "\n",
    "# Drop rows with NaN values\n",
    "video_df.dropna(subset=['viewCount', 'likeCount', 'commentCount'], inplace=True)\n",
    "\n",
    "# Convert columns to int type\n",
    "video_df = video_df.astype({\"viewCount\": int, \"likeCount\": int, \"commentCount\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df49a733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove the particular columns for further analysis\n",
    "column_names = video_df.columns.values.tolist()\n",
    "columns_removed = [\"favouriteCount\",\"caption\",\"duration\",\"definition\",\"video_id\",\"tags\", \"description\",\"tagCount\"]\n",
    "\n",
    "# create new list using list comprehension\n",
    "column_names = [i for i in column_names if i not in columns_removed]\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12601c2-ad2a-4911-bca1-084e5e1e70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = video_df[\"channelTitle\"].unique().tolist()\n",
    "joined = ('_or_').join(file_name).replace(' ', '_').lower()\n",
    "\n",
    "# Create directory\n",
    "dirName = f\"/Users/your_folder/{joined}\"\n",
    "\n",
    "# Create target Directory if don't exist\n",
    "if not os.path.exists(dirName):\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de602f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create path and save df as csv\n",
    "path = f\"/Users/your_folder/{joined}/stats_{joined}.csv\"\n",
    "video_df.to_csv(path, index=False, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b5dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save df as csv\n",
    "video_df_before =video_df[video_df[\"publishedAt\"]< \"2023-02-06\"]\n",
    "\n",
    "path2= f\"/Users/your_folder/media_stats/{joined}/{joined}_b4.csv\"\n",
    "video_df_before.to_csv(path2, index=False, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b350c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df as csv\n",
    "video_df_after =video_df[video_df[\"publishedAt\"]>= \"2023-02-06\"]\n",
    "\n",
    "path3= f\"/Users/your_folder/media_stats/{joined}/{joined}_aft.csv\"\n",
    "video_df_after.to_csv(path3, index=False, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0b6fc-b1b1-455a-9ed2-252967fabf7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f72b4-34c9-48ba-8df5-c42a559f7e3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9279f9c-9cf0-4f95-8b9d-407891a1b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video subscribers/video ratio\n",
    "channel_stats[\"subscribers_per_video\"] = round((channel_stats[\"subscribers\"])/(channel_stats[\"totalVideos\"]),0)\n",
    "\n",
    "# Video view/video ratio\n",
    "channel_stats[\"view_per_video\"] = round((channel_stats[\"views\"])/channel_stats[\"totalVideos\"],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f8239-bf7e-485d-bc00-e748fe1cecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of the current month \n",
    "today = datetime.now()\n",
    "current_month = int(today.strftime(\"%m\"))\n",
    "print(\"Current Month with Decimal Number :\", current_month);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc7a95-b305-4f4f-b40d-134b1669113b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Total - Monthly Video Uploads after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15ee09-b54b-420b-ac10-9a68969defb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_after_per_month = video_df_after.groupby('Month', as_index =False).size()\n",
    "sort_order=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec',]\n",
    "video_after_per_month.index = pd.CategoricalIndex(video_after_per_month['Month'], categories = sort_order, ordered= True)\n",
    "\n",
    "video_after_per_month.reset_index(drop=True, inplace=True)\n",
    "video_after_per_month = video_after_per_month.rename(columns={'size': 'monthly_video_count_after'})\n",
    "video_after_per_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e7de8-5611-473f-977b-54669406af99",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Total - Upload Mins after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38156a-e33c-4f88-b5f8-5a0ba92282a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mins_after_per_month = video_df_after.groupby([\"Year\",\"Month\"])['durationMins'].sum().unstack(level='Year').replace('nan', np.nan).fillna(0)\n",
    "mins_after_per_month = pd.DataFrame(data=mins_after_per_month).reset_index().set_axis(['Month', 'mins_after_per_month'], axis=1)\n",
    "mins_after_per_month\n",
    "\n",
    "merged_df1 = video_after_per_month.merge(mins_after_per_month, left_on='Month', right_on='Month')\n",
    "merged_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949e9a8-82b5-4297-8743-f2fa64eb5af1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Total - Video likes after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b6a4e-fad6-40dc-bf29-da31245bdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_after_per_month = video_df_after.groupby([\"Year\",\"Month\"])['likeCount'].sum().unstack(level='Year').replace('nan', np.nan).fillna(0)\n",
    "likes_after_per_month = pd.DataFrame(data=likes_after_per_month).reset_index().set_axis(['Month', 'likes_after_per_month'], axis=1)\n",
    "likes_after_per_month\n",
    "\n",
    "merged_df2 = merged_df1.merge(likes_after_per_month, left_on='Month', right_on='Month')\n",
    "merged_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89e86a-4d1b-44ce-843c-d3146b65790b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Total Video views after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a568e01-43db-47aa-bada-5fa17c84b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_after_per_month = video_df_after.groupby([\"Year\",\"Month\"])['viewCount'].sum().unstack(level='Year').replace('nan', np.nan).fillna(0)\n",
    "views_after_per_month = pd.DataFrame(data=views_after_per_month).reset_index().set_axis(['Month', 'views_after_per_month'], axis=1)\n",
    "views_after_per_month\n",
    "\n",
    "merged_df3 = merged_df2.merge(views_after_per_month, left_on='Month', right_on='Month')\n",
    "merged_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feac1650-c9d8-4043-be64-e3eb9fb63a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Total - Video comments after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f611e-95a1-44b9-83f6-c07f70ddcd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_after_per_month = video_df_after.groupby([\"Year\",\"Month\"])['commentCount'].sum().unstack(level='Year').replace('nan', np.nan).fillna(0)\n",
    "comments_after_per_month = pd.DataFrame(data=comments_after_per_month).reset_index().set_axis(['Month', 'comments_after_per_month'], axis=1)\n",
    "comments_after_per_month\n",
    "\n",
    "merged_df4 = merged_df3.merge(comments_after_per_month, left_on='Month', right_on='Month')\n",
    "merged_df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d011bc6-131b-4751-ba04-c5417ddb648c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Totals - merged & saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e6fb9-6d89-4fb9-85aa-98783263b0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df4[\"channelName\"] = \"\"\n",
    "merged_df4['channelName'] = merged_df4['channelName'].replace([''], channel_stats[\"channelName\"].tolist())\n",
    "merged_df4.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Define the new row values\n",
    "new_row = merged_df4.loc[0:2,:].values.tolist()\n",
    "\n",
    "# Open the existing CSV file for reading\n",
    "with open('/Users/your_folder/monthly_totals.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Add the new row to the list of rows\n",
    "rows.extend(new_row)\n",
    "\n",
    "# Open the CSV file for writing and write the updated rows\n",
    "with open('/Users/your_folder/monthly_totals.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f66f0-3ad2-4fd4-a9bd-9a62acec3742",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ratios after 6th of Feb, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77093ad8-ceb5-42f1-a591-e25ac12b0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video uploaded after 6th of Feb, 2023\n",
    "video_count_after = video_df_after[\"title\"].count()\n",
    "channel_stats[\"video_count_after\"] = video_count_after # Checked\n",
    "\n",
    "# Video durationSecs after 6th of Feb, 2023\n",
    "secs_count_after = int(video_df_after[\"durationSecs\"].sum())\n",
    "channel_stats[\"secs_count_after\"] = secs_count_after # Checked\n",
    "\n",
    "# Video durationMins after 6th of Feb, 2023\n",
    "mins_count_after = round(video_df_after[\"durationMins\"].sum(),1)\n",
    "channel_stats[\"mins_count_after\"] = mins_count_after # Checked\n",
    "\n",
    "# Video durationHours after 6th of Feb, 2023\n",
    "hours_count_after = round(video_df_after[\"durationHours\"].sum(),1)\n",
    "channel_stats[\"hours_count_after\"] = hours_count_after # Checked\n",
    "\n",
    "# Video views after 6th of Feb, 2023\n",
    "view_count_after = video_df_after[\"viewCount\"].sum()\n",
    "channel_stats[\"view_count_after\"] = view_count_after # Checked\n",
    "\n",
    "# Video likes after 6th of Feb, 2023\n",
    "like_count_after = video_df_after[\"likeCount\"].sum()\n",
    "channel_stats[\"like_count_after\"] = like_count_after # Checked\n",
    "\n",
    "# Video comments after 6th of Feb, 2023\n",
    "comment_count_after = video_df_after[\"commentCount\"].sum()\n",
    "channel_stats[\"comment_count_after\"] = comment_count_after # Checked\n",
    "\n",
    "# Video comment/video ratio after 6th of Feb, 2023\n",
    "comment_per_video_after = round(comment_count_after/video_count_after,0)\n",
    "channel_stats[\"comment_per_video_after\"] = comment_per_video_after\n",
    "\n",
    "# Video view/video ratio after 6th of Feb, 2023\n",
    "view_per_video_after = round(view_count_after/video_count_after,0)\n",
    "channel_stats[\"view_per_video_after\"] = view_per_video_after\n",
    "\n",
    "# Video like/video ratio after 6th of Feb, 2023\n",
    "like_per_video_after = round(like_count_after/video_count_after,0)\n",
    "channel_stats[\"like_per_video_after\"] = like_per_video_after\n",
    "\n",
    "# Video secs/video ratio after 6th of Feb, 2023\n",
    "secs_per_video_after = round(secs_count_after/video_count_after,1)\n",
    "channel_stats[\"secs_per_video_after\"] = secs_per_video_after\n",
    "\n",
    "# Video mins/video ratio after 6th of Feb, 2023\n",
    "mins_per_video_after = round(mins_count_after/video_count_after,1)\n",
    "channel_stats[\"mins_per_video_after\"] = mins_per_video_after\n",
    "\n",
    "# Video hours/video ratio after 6th of Feb, 2023\n",
    "hours_per_video_after = round(hours_count_after/video_count_after,1)\n",
    "channel_stats[\"hours_per_video_after\"] = hours_per_video_after\n",
    "\n",
    "# Video like/comment ratio after 6th of Feb, 2023\n",
    "channel_stats[\"like_per_comment_after\"] = round(like_count_after/comment_count_after,1)\n",
    "\n",
    "# Video view/like ratio after 6th of Feb, 2023\n",
    "channel_stats[\"view_per_like_after\"] = round(view_count_after/like_count_after,1)\n",
    "\n",
    "channel_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e868ab-0d12-4b47-8794-8872dc888dc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ratios before 6th of Feb, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261bf36-e966-49ec-b14a-5814f997bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video uploaded before 6th of Feb, 2023\n",
    "video_count_before = int(channel_stats[\"totalVideos\"]) - video_count_after\n",
    "channel_stats[\"video_count_before\"] = video_count_before # Checked\n",
    "\n",
    "# Video views before 6th of Feb, 2023\n",
    "view_count_before = int(channel_stats[\"views\"]) - view_count_after\n",
    "channel_stats[\"view_count_before\"] = view_count_before # Checked\n",
    "\n",
    "# Video view/video ratio before 6th of Feb, 2023\n",
    "view_per_video_before = round(view_count_before/video_count_before,1)\n",
    "channel_stats[\"view_per_video_before\"] = view_per_video_before # Checked\n",
    "\n",
    "# channel_stats.reset_index(drop=True, inplace=True)\n",
    "channel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59208f83-f5ce-44a4-8f0e-fcede7d0fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_new = channel_stats.columns.values.tolist()\n",
    "channel_stats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Define the new row values\n",
    "new_row = channel_stats.loc[0,:].values.tolist()\n",
    "\n",
    "# Open the existing CSV file for reading\n",
    "with open('/Users/your_folder/media_stats_edited.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Add the new row to the list of rows\n",
    "rows.append(new_row)\n",
    "\n",
    "# Open the CSV file for writing and write the updated rows\n",
    "with open('/Users/your_folder/media_stats_edited.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61af43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20401490",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Best Performing Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(10,6)})\n",
    "ax = sns.barplot(x = 'title', y = 'viewCount', data = video_df.sort_values('viewCount', ascending=False)[0:9])\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos:'{:,.0f}'.format(x/1000) + 'K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f5cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(10,6)})\n",
    "ax = sns.barplot(x = 'title', y = 'viewCount', data = video_df_before.sort_values('viewCount', ascending=False)[0:9])\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set(title='After Earthquake 6th Feb 2023')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos:'{:,.0f}'.format(x/1000) + 'K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(10,6)})\n",
    "ax = sns.barplot(x = 'title', y = 'viewCount', data = video_df_before.sort_values('viewCount', ascending=False)[0:9])\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set(title='Before Earthquake 6th Feb 2023')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos:'{:,.0f}'.format(x/1000) + 'K'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769540b7",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### Worst performing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fcd1c9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x = 'title', y = 'viewCount', data = video_df.sort_values('viewCount', ascending=True)[0:9])\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.bar_label(ax.containers[0], label_type='edge')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos:'{:,.0f}'.format(x/1000) + 'K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87051027",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x = 'title', y = 'viewCount', data = video_df_after.sort_values('viewCount', ascending=True)[0:9])\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.bar_label(ax.containers[0], label_type='edge')\n",
    "ax.set(title='After Earthquake 6th Feb 2023')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos:'{:,.0f}'.format(x/1000) + 'K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40179ab0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x = 'title', y = 'viewCount', data = video_df_before.sort_values('viewCount', ascending=True)[0:9])\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.bar_label(ax.containers[0], label_type='edge')\n",
    "ax.set(title='Before Earthquake 6th Feb 2023')\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos:'{:,.0f}'.format(x/1000) + 'K'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1a6fc",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### View distribution per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753030ac",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(video_df['channelTitle'], video_df['viewCount'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c972f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(video_df_after['channelTitle'], video_df_after['viewCount']).set(title='After Earthquake 6th Feb 2023')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91405180",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(video_df_before['channelTitle'], video_df_before['viewCount']).set(title='Before Earthquake 6th Feb 2023')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3ab64",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Views vs. likes and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='likeCount', y='viewCount',hue= 'commentCount', data= video_df)\n",
    "ax.ticklabel_format(style='plain')\n",
    "# ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d670085",
   "metadata": {},
   "source": [
    "#### After Earthquake on 6th Feb 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb8add",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='likeCount', y='viewCount',hue= 'commentCount', data= video_df_after)\n",
    "ax.ticklabel_format(style='plain')\n",
    "# ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347fc2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Before Earthquake on 6th Feb 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a61f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='likeCount', y='viewCount',hue= 'commentCount', data= video_df_before)\n",
    "ax.ticklabel_format(style='plain')\n",
    "# ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4917bd",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### Video duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871c102",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = video_df, x = 'durationSecs', bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81e97e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = video_df_before[video_df_before[\"durationSecs\"]<50000], x = 'durationSecs', bins=100).set(title='Before Earthquake 6th Feb 2023')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b411c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = video_df_after, x = 'durationSecs', bins=100).set(title='After Earthquake 6th Feb 2023')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f8d2e",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "### Wordcloud for video titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51512c11",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "source": [
    "#### After Earthquake 6th Feb 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0dd46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "video_df_after['title_no_stopwords'] = video_df_after['title'].apply(lambda x: [item for item in str(x).split() if item not in stop_words])\n",
    "\n",
    "all_words = list([a for b in video_df_after['title_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words) \n",
    "\n",
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\");\n",
    "\n",
    "wordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black', \n",
    "                      colormap='viridis', collocations=False).generate(all_words_str)\n",
    "plot_cloud(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bc4cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Upload schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc286ff3-76bc-4bcc-a13f-741be2cc444b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Daily Upload After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c6652-76bc-4aaa-a6f7-c8ace1b389ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Set the specific date and time\n",
    "start_date = datetime.datetime(2023, 2, 6, 4, 17, 0)  # Year, Month, Day, Hour, Minute, Second\n",
    "end_date =datetime.datetime.now()\n",
    "\n",
    "# Define the days of the week to count\n",
    "days_of_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "# Initialize an empty dictionary to store the counts\n",
    "counts = {}\n",
    "\n",
    "# Loop through the days of the week and count the number of occurrences\n",
    "for day in days_of_week:\n",
    "    count = 0\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        if current_date.strftime(\"%A\") == day:\n",
    "            count += 1\n",
    "        current_date += datetime.timedelta(days=1)\n",
    "    counts[day] = count\n",
    "\n",
    "# Convert the counts to a pandas dataframe and display the result\n",
    "count_days_after = pd.DataFrame.from_dict(counts, orient=\"index\", columns=[\"pushblishDayName\"])\n",
    "count_days_after = count_days_after.reset_index().set_axis(['pushblishDayName', 'count'], axis=1)\n",
    "count_days_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e59a3-2138-4f85-9c1f-074b0ae6df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_daily_video_after = pd.DataFrame(video_df_after['pushblishDayName'].value_counts()).reset_index().set_axis(['pushblishDayName', 'video_daily_after'], axis=1)\n",
    "avg_daily_video_after = avg_daily_video_after.merge(count_days_after, how='left', on='pushblishDayName')\n",
    "avg_daily_video_after[\"daily_counts\"] = round((avg_daily_video_after[\"video_daily_after\"] / avg_daily_video_after[\"count\"]),1)\n",
    "\n",
    "# create a categorical data type for the days of the week\n",
    "cat_type = pd.api.types.CategoricalDtype(categories=days_of_week, ordered=True)\n",
    "avg_daily_video_after['pushblishDayName'] = avg_daily_video_after['pushblishDayName'].astype(cat_type)\n",
    "\n",
    "# sort the dataframe based on the categorical data type\n",
    "avg_daily_video_after = avg_daily_video_after.sort_values('pushblishDayName')\n",
    "\n",
    "avg_daily_video_after.reset_index(drop=True, inplace=True)\n",
    "\n",
    "avg_daily_video_after[\"channelName\"] = \"\"\n",
    "avg_daily_video_after['channelName'] = avg_daily_video_after['channelName'].replace([''], channel_stats[\"channelName\"].tolist())\n",
    "avg_daily_video_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8fad5b-95b4-49f3-b0dc-5c2e76785e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_daily_video_after.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Define the new row values\n",
    "new_row = avg_daily_video_after.loc[0:7,:].values.tolist()\n",
    "\n",
    "# Open the existing CSV file for reading\n",
    "with open('/Users/gulecs/Desktop/youtube api/media_stats/daily_totals.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Add the new row to the list of rows\n",
    "rows.extend(new_row)\n",
    "\n",
    "# Open the CSV file for writing and write the updated rows\n",
    "with open('/Users/gulecs/Desktop/youtube api/media_stats/daily_totals.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f355fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = avg_daily_video_after.plot.bar(x='pushblishDayName', y='daily_counts', rot=0, xlabel=\"\")\n",
    "ax.bar_label(ax.containers[0], label_type='edge')\n",
    "ax.set(title='After Earthquake 6th Feb 2023')\n",
    "ax.get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de5bfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Monthly Upload After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce2c8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax2_1 = sns.barplot(x='Month', y='monthly_video_count_after', data=video_after_per_month, order=sort_order)\n",
    "ax2_1.bar_label(ax2_1.containers[0], label_type='edge')\n",
    "ax2_1.set(title='After Earthquake 6th Feb 2023')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
